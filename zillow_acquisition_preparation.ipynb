{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654d9dd1",
   "metadata": {},
   "source": [
    "# ZILLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d9b0a1",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from env import host, user, password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a32828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a string that connects me to MySQLWorkbench\n",
    "\n",
    "def get_connection(db, user=user, host=host, password=password):\n",
    "    '''\n",
    "    get_connection uses login info from env.py file to access Codeup db.\n",
    "    It takes in a string name of a database as an argument.\n",
    "    '''\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40706c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data from the Codeup database\n",
    "\n",
    "def get_zillow_data():\n",
    "    '''\n",
    "    get_zillow_data() gets the zillow (only properties_2017 table) data from Codeup db, then writes it to a csv file,\n",
    "    and returns the DF.\n",
    "    '''\n",
    "    # Creating a SQL query\n",
    "    sql_query = '''\n",
    "                SELECT DISTINCT *,\n",
    "                    pred17.logerror,\n",
    "                    pred17.transactiondate,\n",
    "                    acd.airconditioningdesc,\n",
    "                    asd.architecturalstyledesc,\n",
    "                    bcd.buildingclassdesc,\n",
    "                    hsd.heatingorsystemdesc,\n",
    "                    sd.storydesc,\n",
    "                    tcd.typeconstructiondesc\n",
    "                FROM properties_2017 AS p17\n",
    "                LEFT JOIN predictions_2017 AS pred17 USING (parcelid)\n",
    "                LEFT JOIN propertylandusetype USING (propertylandusetypeid)\n",
    "                LEFT JOIN airconditioningtype AS acd USING (airconditioningtypeid)\n",
    "                LEFT JOIN architecturalstyletype AS asd USING (architecturalstyletypeid)\n",
    "                LEFT JOIN buildingclasstype AS bcd USING (buildingclasstypeid)\n",
    "                LEFT JOIN heatingorsystemtype AS hsd USING (heatingorsystemtypeid)\n",
    "                LEFT JOIN storytype AS sd USING (storytypeid)\n",
    "                LEFT JOIN typeconstructiontype AS tcd USING (typeconstructiontypeid)\n",
    "                JOIN (SELECT MAX(transactiondate BETWEEN '2017-01-01' AND '2017-12-31') AS max_sale_date\n",
    "                     FROM predictions_2017 AS pred17) AS pred17\n",
    "                WHERE propertylandusedesc = 'Single Family Residential'\n",
    "                AND longitude IS NOT NULL\n",
    "                AND latitude IS NOT NULL;\n",
    "                '''\n",
    "    \n",
    "    # Reading in the DataFrame from Codeup db.\n",
    "    df = pd.read_sql(sql_query, get_connection('zillow'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ee3f8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assigning the dataframe to a variable and displaying of it to have a first look\n",
    "\n",
    "houses = get_zillow_data()\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ecffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying number of rows and columns\n",
    "\n",
    "houses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0262991",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Displaying some general information about the data\n",
    "\n",
    "houses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b99d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing houses to csv on my computer\n",
    "\n",
    "houses.to_csv('houses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb53ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying a first statistical analysis of the data through .describe()\n",
    "\n",
    "houses.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying statistical analysis of the data through.descibe()\n",
    "# with astype('int64') to cut through all the noise of the float data\n",
    "\n",
    "houses.describe().T.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ecd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e842dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates\n",
    "\n",
    "houses.columns.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df0e224",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dropping the duplicates\n",
    "\n",
    "houses.drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c26ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see the number of columns left\n",
    "\n",
    "houses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a list of the columns to detect the duplicates\n",
    "\n",
    "houses.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bad77b",
   "metadata": {},
   "source": [
    "**The duplicates are 2 id columns. They are not essential to the data exploration. I will drop them along with other id columns**\n",
    "\n",
    "**However in case one of the columns are necessary in a different case, I have put together a function that rename the columns in order to differentiate them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f3058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For loop to rename duplicate columns (particularly if they have the same name and not the same content)\n",
    "\n",
    "# cols=pd.Series(df.columns)\n",
    "# for dup in df.columns[df.columns.duplicated(keep=False)]: \n",
    "#     cols[df.columns.get_loc(dup)] = ([dup + '_' + str(d_idx) \n",
    "#                                      if d_idx != 0 \n",
    "#                                      else dup \n",
    "#                                      for d_idx in range(df.columns.get_loc(dup).sum())]\n",
    "#                                     )\n",
    "# df.columns=cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5236da20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dropping id columns\n",
    "\n",
    "houses = houses.drop(['typeconstructiontypeid',\n",
    " 'storytypeid',\n",
    " 'heatingorsystemtypeid',\n",
    " 'architecturalstyletypeid',\n",
    " 'airconditioningtypeid',\n",
    " 'propertylandusetypeid',\n",
    " 'id',\n",
    " 'buildingqualitytypeid',\n",
    " 'pooltypeid10',\n",
    " 'pooltypeid2',\n",
    " 'pooltypeid7',\n",
    " 'decktypeid'], axis = 1)\n",
    "houses.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406701aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cd27cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# A loop to print out the value_counts of the columns\n",
    "\n",
    "for column in houses.columns:\n",
    "    print(column)\n",
    "    print(houses[column].value_counts())\n",
    "    print('\\n##########################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deadfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This code allows me to display the count of nulls in each column mentioned\n",
    "# # Still need to shape it into a function or a loop\n",
    "\n",
    "# houses[['bedroomcnt',\n",
    "#  'calculatedbathnbr',\n",
    "#  'finishedfloor1squarefeet',\n",
    "#  'calculatedfinishedsquarefeet',\n",
    "#  'finishedsquarefeet12',\n",
    "#  'finishedsquarefeet15',\n",
    "#  'finishedsquarefeet50',\n",
    "#  'finishedsquarefeet6']].isna().sum().reset_index(name=\"n\").plot.bar(x='index', y='n', rot=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4984eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying my function\n",
    "\n",
    "def multi_frequency(df,vars):\n",
    "    '''multi_frequency takes a dataframe in *arg and a *kwarg in the form of a list of columns\n",
    "    and return a dataframe with the count and the frequency of the data\n",
    "    '''\n",
    "    frequency=df[vars].isnull().sum()\n",
    "    percentage=df[vars].isnull().sum()*100/(len(df))\n",
    "    df=pd.concat([frequency,percentage], axis=1, keys=['num_rows_missing', 'pct_rows_missing'])\n",
    "    return df\n",
    "multi_frequency(houses, ['latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191399b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the columns and their the count and percent of missing rows ordered by percent in a descending order\n",
    "\n",
    "multi_frequency(houses, houses.columns).sort_values(by='pct_rows_missing', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multi_frequency_rows(df,vars):\n",
    "#     '''multi_frequency takes a dataframe in *arg and a *kwarg in the form of a list of columns\n",
    "#     and return a dataframe with the count and the frequency of the data\n",
    "#     '''\n",
    "#     frequency=df[vars].isnull().sum(axis=1)\n",
    "#     percentage=df[vars].isnull().sum(axis=1)*100/(len(df))\n",
    "#     df=pd.concat([frequency,percentage], axis=1, keys=['num_entries_missing', 'pct_entries_missing'])\n",
    "#     return df\n",
    "# multi_frequency(houses, ['basementsqft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the table above to a variable and selecting a cut off for the percentage of rows missing to eliminate\n",
    "\n",
    "frequency = multi_frequency(houses, houses.columns).sort_values(by='pct_rows_missing', ascending=False)\n",
    "frequency.pct_rows_missing >= 33.589411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710505bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percent of columns that is missing +30% of its entries\n",
    "\n",
    "percent_nullvalues_columns = (len(frequency[frequency.pct_rows_missing >= 33.589411]))/len(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_nullvalues_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b098ab",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "- 54.71% of the data is missing between 33% and 100% of its values\n",
    "- This makes me think that the best cut off would be the 33% threshold\n",
    "- Many columns are id columns and should be removed. They have no impact on the analysis of the data and teh dataframe already has parcelid as unique identifier. Here is the list of the columns to drop:\n",
    "     'typeconstructiontypeid',\n",
    "     'storytypeid',\n",
    "     'heatingorsystemtypeid',\n",
    "     'buildingclasstypeid',\n",
    "     'architecturalstyletypeid',\n",
    "     'airconditioningtypeid',\n",
    "     'propertylandusetypeid',\n",
    "     'id',\n",
    "     'buildingqualitytypeid',\n",
    "     'id_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f6d6a",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482f95ec",
   "metadata": {},
   "source": [
    "## 1. Remove any properties that are likely to be something other than single unit properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b3d221",
   "metadata": {},
   "source": [
    "**Single unit properties were selected in the SQL query. The code for it is shown in the SQL query**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd3460e",
   "metadata": {},
   "source": [
    "## 2. Create a function that will drop rows or columns based on the percent of values that are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ab3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5306ad7",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A. Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5c7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, prop_required_column, prop_required_row):\n",
    "    '''\n",
    "    handle_missing_values calculates the number of recquired columns and rows\n",
    "    based on an arbitrary prop_required_row/column float times the number\n",
    "    of columns/rows respectively as ordered in the function\n",
    "    then uses the 'thresh' argument to apply that number to the dropna function\n",
    "    '''\n",
    "    required_columns = df.shape[0] * prop_required_column\n",
    "    required_rows = df.shape[1] * prop_required_row\n",
    "    \n",
    "    df = df.dropna(axis=0, thresh = required_rows)\n",
    "    df = df.dropna(axis=1, thresh = required_columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6a967",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "houses = handle_missing_values(houses, prop_required_column=.7, prop_required_row=.7) \n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_and_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce7d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _maybe_dedup_names(self, names):\n",
    "    # see gh-7160 and gh-9424: this helps to provide\n",
    "    # immediate alleviation of the duplicate names\n",
    "    # issue and appears to be satisfactory to users,\n",
    "    # but ultimately, not needing to butcher the names\n",
    "    # would be nice!\n",
    "    if self.mangle_dupe_cols:\n",
    "        names = list(names)  # so we can index\n",
    "        counts = {}\n",
    "\n",
    "        for i, col in enumerate(names):\n",
    "            cur_count = counts.get(col, 0)\n",
    "\n",
    "            if cur_count > 0:\n",
    "                names[i] = '%s.%d' % (col, cur_count)\n",
    "\n",
    "            counts[col] = cur_count + 1\n",
    "\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa1007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax1 = plt.subplots()\n",
    "ax1.plot(df.iloc[:,0],df.iloc[:,1],linewidth=0.5,zorder=1, label = )\n",
    "ax1.plot(df.iloc[:,0],df.iloc[:,2],linewidth=0.5,zorder=1, label = )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
